{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "y8DNMLjGs1Cc"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashchougule19/Nudging_low_carbon_behavior/blob/davidstintz/prototype_group3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Seminar Information System Group 3: Prototype**\n"
      ],
      "metadata": {
        "id": "kSJCX317Z4Dc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kty-WJ43bL2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Introduction**"
      ],
      "metadata": {
        "id": "7ma6B8LFbNms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NILM (Non-Intrusive Load Monitoring)** is a technique in energy analytics designed to break down aggregate energy consumption data from a single measurement point into detailed, appliance-level usage patterns.\n",
        "\n",
        "The primary advantage of NILM is that it can determine the energy consumption of individual devices without requiring individual measuinrg for each appliance. Instead, it analyzes total energy usage, typically collected by a single sensor, and applies machine learning or signal processing techniques to disaggregate the data into components corresponding to various appliances.\n",
        "The benefits are numerous. Not only does it help household occupants better understand and reduce their energy consumption, but it also enables appliance-specific financial savings. This, in turn, leads to lower electricity bills and a reduced carbon footprint.\n",
        "\n",
        "The field has experienced rapid growth recently, driven by the widespread adoption of smart meters in numerous countries. However, empirically comparing disaggregation algorithms remains a significant challenge. This difficulty arises from the use of diverse datasets, the absence of standardized reference implementations, and the variety of accuracy metrics employed. *(Batra et al 2014)*.\n",
        "\n",
        "To address these challenges, Batra et al  introduced the **Non-Intrusive Load Monitoring Toolkit (NILMTK)** —an open-source toolkit designed to facilitate reproducible and consistent comparisons of energy disaggregation algorithms.\n",
        "\n",
        "\n",
        "This notebook provides an overview of recent advancements in the field of NILM, exploring its practical implications and applications. It begins with a review of the latest scientific articles, highlighting the most promising approaches and models in the field. The analysis then moves to empirical dataset with energy consumption data from a private household, where selected methods from the literature are applied and compared. Finally, the conclusion section discusses the results, reflects on key findings, and provides an outlook on future directions for NILM research and applications."
      ],
      "metadata": {
        "id": "e3_fquHZejRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Literature Review**\n"
      ],
      "metadata": {
        "id": "RaYwoGknaY8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2.1 Emerging of NILM-TK and reason-why**\n",
        "\n",
        "The seminal work of Batra et al. (2014) highlighted the pressing need for an open-source toolkit to facilitate better analysis and benchmarking of energy disaggregation algorithms. Their goal was to address three core obstacles that hindered the comparison of state-of-the-art approaches in the field:\n",
        "\n",
        "**Limited Dataset Evaluation:**\n",
        "Most papers at the time were evaluated on a single dataset, making it difficult to assess whether the results could generalize to new households. Furthermore, researchers often sub-sampled datasets for specific households, appliances, or time periods, which created challenges in reproducing empirical results.\n",
        "\n",
        "**Inconsistent Benchmarks:**\n",
        "New approaches were rarely compared against the same benchmark algorithms, complicating efforts to perform empirical comparisons across different studies.\n",
        "\n",
        "**Divergent Evaluation Metrics:**\n",
        "Papers targeted different NILM use cases and employed varying sets of evaluation metrics, making it nearly impossible to directly compare results across publications.\n",
        "\n",
        "To address these challenges, Batra et al. introduced NILMTK—an open-source toolkit for the comparative analysis of energy disaggregation algorithms, which decompose aggregate household energy consumption into individual appliance-level usage. It provides a complete pipeline from data sets to performance metrics.\n",
        "\n",
        "One of **NILMTK's key contributions** is the development of a standardized data format, NILMTK-DF. Based on the widely-used REDD dataset format, NILMTK-DF ensures compatibility across multiple datasets, making it easier for the research community to adopt. The toolkit also includes parsers for six publicly available datasets, further enabling reproducibility and fostering collaboration within the NILM community.\n",
        "Additionally, statistical functions providing understanding of the dataset as well as preprocessing functions to ease common data set challenges are provided by the creators of NILMTK.\n",
        "\n",
        "2 benchmark approaches are provided:\n",
        "- approach based on combinatorial optimisation\n",
        "- apporach based on factorial hidden Markov model\n",
        "\n",
        "wide range of accuracy metrics enabling evaluation of any disaggregation algorith compatible with NILMTK.\n",
        "\n",
        "REDD - Reference Enegery Disaggregation Dataset (2011): first publicily available dataset collected specifically to NILM research: aggregate + sub-metered power data from 6 households\n",
        "\n",
        "2012: BLUED (Building-Level fUlly-labeled dataset for Electricity Disaggregation: containing data from one single household. contains only appliance-states (e.g. washing machine turned on or off)\n",
        "\n",
        "based con scikit-learn\n",
        "but allos for specific requirements to energy disaggregation domain, such as\n",
        "- data set parsers\n",
        "- benchmark disaggregation algorithms\n",
        "- engergy disaggregation metrics\n",
        "\n",
        "\n",
        "\n",
        "Reference to NILMTK website:https://nilmtk.github.io/"
      ],
      "metadata": {
        "id": "I1UJt0krH6PU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) Further contributions to the original work of Batra et al (2014)**\n",
        "\n"
      ],
      "metadata": {
        "id": "781IntOxIfZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**c) Recent scientific research in the field of NILM-TK**"
      ],
      "metadata": {
        "id": "8_nxghvqIflP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2 Common NILM approaches from literature\n",
        "\n",
        "**1. Combinatorial Optimization (OO)**\n",
        "\n",
        "NILM assumes that the total load can be considered as a sum of the loads of individual appliacations. Their load depends on the position of the switch an ON or OFF state. As a consequence of that, modeling an appliance that is either ON or OFF at a given time t generates a Boolean vector.\n",
        "\n",
        "\n",
        "ˆ(t) = arg min |P (t) − a\n",
        "aiPi|,\n",
        "\n",
        "\n",
        "**2 Factorial Hidden Markov Model (FHMM)**\n",
        "\n",
        "Hidden Markov Models (HMM) are statistical Markov models used to represent systems that have hidden states (unobservable) but generate observable outputs based on those states. It’s widely applied in fields like speech recognition, bioinformatics, and finance for problems involving sequences of data.\n",
        "\n",
        "In the context of energy disaggregation, the total power signal at the output of smart meter or an inhouse measurement device can be considered as a linear sum of power signals as appliances change their states. Assuming that each appliance evolves time independently whose state follows a Markov model, their combination can be best modeled by factorial hidden Markov model. Instead of a traditional HMM, treating the state space as a monolithic set of states, it factors the state into multiple variables or components, making it more scalable for complex systems with large or multidimensional state spaces. (Ngyuen 2020).\n",
        "\n",
        "\n",
        "**3. Hart's Algorithm (Hart85)**\n",
        "The works of George Hart trace back to the mid-80s and can be considered as one of the pioneering works for NILM (Ngyuen). Hart developed a prototype designed for load research in a non-intrusive manner.\n",
        "The prototype consists of a microprocessor measuring changes in the target residential load and an algorithm that disaggregates the load to individual appliance loads.\n",
        "The algorithm includes eight steps, with edge detection, clustering, and ON/OFF matching as the primary components:\n",
        "\n",
        "Edge Detection: Identifies power changes by separating steady and transitional periods (minimum thresholds: 2 seconds, 15 W/VAR) and calculates total power change during transitions.\n",
        "Clustering: Groups power changes into clusters, with positive changes indicating appliances turning ON and negative changes indicating OFF.\n",
        "ON/OFF Matching: Matches opposite changes of similar magnitude over time to form appliance cycles.\n",
        "\n",
        "\n",
        "**4. Maximum Likelihood Estmiation (MLE)**\n",
        "MLE is statistical method used to estimate the parameters of a probabilistic model. It identifies the values of the model's parameters that maximize the likelihood of observing the given data.\n",
        "The concept behind MLE is to find the parameter values that make the observed data most likely. The likelihood function measures how well the model with specific parameters explains the observed data.\n",
        "\n",
        "\n",
        "**Further Approaches**\n",
        "\n",
        "- Discriminative Sparse Coding\n",
        "- RNN\n",
        "- Denoising Auto Encoder\n",
        "- Seq2Point\n",
        "- Seq2Seq\n",
        "- WindowGRU\n",
        "- Third-party NILM algorithms which work with NILMTK: Latent Bayesian Melding (github), Neural NILM by Jack Kelly (github)\n",
        "\n"
      ],
      "metadata": {
        "id": "wE94tttFZVGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.3 check-industry-developed approaches and figure out which baseline is used for comparison"
      ],
      "metadata": {
        "id": "_Xl63dRFmhEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.4 table with approaches and algortihm"
      ],
      "metadata": {
        "id": "y8DNMLjGs1Cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**>>place Sashas overview here**\n",
        "https://docs.google.com/spreadsheets/d/115JlRYo-rpbel2f8-NiP3zitk4wZtqQthIVGdxr2UnA/edit?gid=0#gid=0\n"
      ],
      "metadata": {
        "id": "DnaFGEkxktr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#url = 'https://docs.google.com/spreadsheets/d/115JlRYo-rpbel2f8-NiP3zitk4wZtqQthIVGdxr2UnA/edit?gid=0#gid=0'\n",
        "#df = pd.read_csv(url, delimiter=',')  # Adjust delimiter as needed\n",
        "#print(df.head())"
      ],
      "metadata": {
        "id": "1gWRZdh-rUyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Data Set**\n"
      ],
      "metadata": {
        "id": "JHRebYSTbFr-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vss6zXWd0RRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Loading of Data Set (Alonas Dataset)"
      ],
      "metadata": {
        "id": "BOsEnBJC0Ryz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preliminaries\n",
        "\n",
        "#installing dependencies\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "#Mount Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TebR_9Zfh0Kh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76668ecc-140f-499e-be1b-abd64f4698cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# **Update File Loading later**\n",
        "\n",
        "#Loading Alonas second file that is corresponding to her code. Exhcange later!\n",
        "dbfile = '/content/drive/My Drive/Seminar IS/home-assistant_v2_second.db'\n",
        "\n",
        "\n",
        "#Loading of correct file:\n",
        "#dbfile = '/content/drive/My Drive/Seminar IS/home-assistant_v2.db'\n",
        "\n",
        "# For a Google Drive file\n",
        "#file_id = \"d/1G90s18POtqP7zRNl0UDO8csof2XUWe1h\"\n",
        "#dbfile = f\"https://drive.google.com/file/d/1G90s18POtqP7zRNl0UDO8csof2XUWe1h/view={file_id}\"\n",
        "#dbfile = f\"https://drive.google.com/uc?id={file_id}\""
      ],
      "metadata": {
        "id": "bNjRkDyv1VCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.path.exists(dbfile))  # Should return True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo2ZwHaRlou2",
        "outputId": "7c7af439-d751-4653-d915-bb33ae4f9f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sql data pulling: accessing the database and storing data tables as separate dfs\n",
        "\n",
        "#with these lines access the sql database\n",
        "con = sqlite3.connect(dbfile)\n",
        "cur = con.cursor()\n",
        "table_list = [a for a in cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table'\")]\n",
        "print(table_list)\n",
        "con.close()\n",
        "\n",
        "#accessing the events data base\n",
        "with sqlite3.connect(dbfile) as con:\n",
        "    cur = con.cursor()\n",
        "    cur.execute(\"SELECT * FROM events\")\n",
        "    events = cur.fetchall()\n",
        "\n",
        "#converting it to the pandas data frame\n",
        "from_events_db = []\n",
        "\n",
        "for result in events:\n",
        "    result = list(result)\n",
        "    from_events_db.append(result)\n",
        "\n",
        "columns = [\"event_id\",\"event_type\",\"event_data\",\"origin\",\"time_fired\",\"created\",\"context_id\",\"context_user_id\",\"context_parent_id\"]\n",
        "events_df = pd.DataFrame(from_events_db, columns = columns)\n",
        "\n",
        "\n",
        "#acessing the schema_changes database\n",
        "with sqlite3.connect(dbfile) as con:\n",
        "    cur = con.cursor()\n",
        "    cur.execute(\"SELECT * FROM schema_changes\")\n",
        "    schema_changes = cur.fetchall()\n",
        "\n",
        "#converting it to the pandas data frame\n",
        "from_schema_changes_db = []\n",
        "\n",
        "for result in schema_changes:\n",
        "    result = list(result)\n",
        "    from_schema_changes_db.append(result)\n",
        "\n",
        "columns = [\"change_id\",\"schema_version\",\"changed\"]\n",
        "schema_changes_df = pd.DataFrame(from_schema_changes_db, columns = columns)\n",
        "\n",
        "#acessing the states database\n",
        "with sqlite3.connect(dbfile) as con:\n",
        "    cur = con.cursor()\n",
        "    cur.execute(\"SELECT * FROM states\")\n",
        "    states = cur.fetchall()\n",
        "\n",
        "\n",
        "#converting it to the pandas data frame\n",
        "from_states_db = []\n",
        "\n",
        "for result in states:\n",
        "    result = list(result)\n",
        "    from_states_db.append(result)\n",
        "\n",
        "columns = [\"state_id\",\"domain\",\"entity_id\",\"state\",\"attributes\",\"event_id\",\"last_changed\",\"last_updated\",\"created\",\"old_state_id\"]\n",
        "states_df = pd.DataFrame(from_states_db, columns = columns)\n",
        "\n",
        "#acessing the statistics database\n",
        "with sqlite3.connect(dbfile) as con:\n",
        "    cur = con.cursor()\n",
        "    cur.execute(\"SELECT * FROM statistics\")\n",
        "    statistics = cur.fetchall()\n",
        "\n",
        "#converting it to the pandas data frame\n",
        "from_statistics_db = []\n",
        "\n",
        "for result in statistics:\n",
        "    result = list(result)\n",
        "    from_statistics_db.append(result)\n",
        "\n",
        "columns = [\"id\",\"created\",\"metadata_id\",\"start\",\"mean\",\"min\",\"max\",\"last_reset\",\"state\",\"sum\"]\n",
        "statistics_df = pd.DataFrame(from_statistics_db, columns = columns)\n",
        "\n",
        "#acessing the statistics_meta database\n",
        "with sqlite3.connect(dbfile) as con:\n",
        "    cur = con.cursor()\n",
        "    cur.execute(\"SELECT * FROM statistics_meta\")\n",
        "    statistics_meta = cur.fetchall()\n",
        "\n",
        "#converting it to the pandas data frame\n",
        "from_statistics_meta_db = []\n",
        "\n",
        "for result in statistics_meta:\n",
        "    result = list(result)\n",
        "    from_statistics_meta_db.append(result)\n",
        "\n",
        "columns = [\"id\",\"statistic_id\",\"source\",\"unit_of_measurement\",\"has_mean\",\"has_sum\",\"name\"]\n",
        "statistics_meta_df = pd.DataFrame(from_statistics_meta_db, columns = columns)\n",
        "\n",
        "\n",
        "#acessing the statistics_runs database\n",
        "with sqlite3.connect(dbfile) as con:\n",
        "    cur = con.cursor()\n",
        "    cur.execute(\"SELECT * FROM statistics_runs\")\n",
        "    statistics_runs = cur.fetchall()\n",
        "\n",
        "#converting it to the pandas data frame\n",
        "from_statistics_runs_db = []\n",
        "\n",
        "for result in statistics_runs:\n",
        "    result = list(result)\n",
        "    from_statistics_runs_db.append(result)\n",
        "\n",
        "columns = [\"run_id\",\"start\"]\n",
        "statistics_runs_df = pd.DataFrame(from_statistics_runs_db, columns = columns)\n",
        "\n",
        "#acessing the statistics_short database\n",
        "with sqlite3.connect(dbfile) as con:\n",
        "    cur = con.cursor()\n",
        "    cur.execute(\"SELECT * FROM statistics_short_term\")\n",
        "    statistics_short_term = cur.fetchall()\n",
        "\n",
        "#converting it to the pandas data frame\n",
        "from_statistics_short_term_db = []\n",
        "\n",
        "for result in statistics_short_term:\n",
        "    result = list(result)\n",
        "    from_statistics_short_term_db.append(result)\n",
        "\n",
        "columns = [\"id\",\"created\",\"start\",\"mean\",\"min\",\"max\",\"last_reset\",\"state\",\"sum\",\"metadata_id\"]\n",
        "statistics_short_term_df = pd.DataFrame(from_statistics_short_term_db, columns = columns)\n",
        "\n",
        "#shapes of these dataframes\n",
        "\n",
        "print(f'The shape of datasets: \\n events: {events_df.shape}, \\n schema_changes : {schema_changes_df.shape}\\n states : {states_df.shape}, \\n statistics : {statistics_df.shape},\\n statistics_meta: {statistics_meta_df.shape},\\n statistics_runs : {statistics_runs_df.shape},\\n statistics_short_term: {statistics_runs_df.shape}')"
      ],
      "metadata": {
        "id": "-TcEF9u-lrKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9825adbc-98d4-4524-b114-34d1a91cb086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('events',), ('recorder_runs',), ('schema_changes',), ('states',), ('statistics_meta',), ('statistics',), ('statistics_short_term',), ('statistics_runs',)]\n",
            "The shape of datasets: \n",
            " events: (508630, 9), \n",
            " schema_changes : (13, 3)\n",
            " states : (507505, 10), \n",
            " statistics : (12340, 10),\n",
            " statistics_meta: (13, 7),\n",
            " statistics_runs : (2954, 2),\n",
            " statistics_short_term: (2954, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unpacking states_df\n",
        "df = states_df.copy()\n",
        "\n",
        "\n",
        "#booleans and missing values are stored in a weird format, fixing it\n",
        "df['attributes'] = df['attributes'].apply(lambda x: x.replace('true','True'))\n",
        "df['attributes'] = df['attributes'].apply(lambda x: x.replace('false','False'))\n",
        "df['attributes'] = df['attributes'].apply(lambda x: x.replace('null','None'))\n",
        "\n",
        "#asking python to access the column and find proper data structure for it\n",
        "df['attributes']=df['attributes'].apply(lambda dat: dict(eval(dat)))\n",
        "df2 = pd.json_normalize(df['attributes'])\n",
        "result = pd.concat([df,df2], axis = 1).drop('attributes', axis = 1)\n",
        "\n",
        "result.head()"
      ],
      "metadata": {
        "id": "cNrVouF853fR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "f3c71aac-bd68-41c9-aad9-0c09d453260b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   state_id  domain                            entity_id  state  event_id  \\\n",
              "0  11244860   zwave                      zwave.switch_cr  ready  11287622   \n",
              "1  11244861  sensor           sensor.switch_cr_exporting  False  11287623   \n",
              "2  11244862  sensor              sensor.switch_cr_energy   6.86  11287624   \n",
              "3  11244863  sensor  sensor.switch_cr_previous_reading_1   6.86  11287625   \n",
              "4  11244864  sensor          sensor.switch_cr_interval_1    301  11287626   \n",
              "\n",
              "                 last_changed                last_updated  \\\n",
              "0  2021-11-28 20:46:35.720593  2021-12-02 03:12:05.162304   \n",
              "1  2021-12-02 03:12:05.162807  2021-12-02 03:12:05.162807   \n",
              "2  2021-12-02 03:12:05.191776  2021-12-02 03:12:05.191776   \n",
              "3  2021-12-02 03:12:05.220377  2021-12-02 03:12:05.220377   \n",
              "4  2021-12-02 03:12:05.252402  2021-12-02 03:12:05.252402   \n",
              "\n",
              "                      created  old_state_id  node_id  ... end start status  \\\n",
              "0  2021-12-02 03:12:05.162304           NaN     15.0  ... NaN   NaN    NaN   \n",
              "1  2021-12-02 03:12:05.162807           NaN     15.0  ... NaN   NaN    NaN   \n",
              "2  2021-12-02 03:12:05.191776           NaN     15.0  ... NaN   NaN    NaN   \n",
              "3  2021-12-02 03:12:05.220377           NaN     15.0  ... NaN   NaN    NaN   \n",
              "4  2021-12-02 03:12:05.252402           NaN     15.0  ... NaN   NaN    NaN   \n",
              "\n",
              "  ignoring_battery_optizimations source_type altitude course speed  \\\n",
              "0                            NaN         NaN      NaN    NaN   NaN   \n",
              "1                            NaN         NaN      NaN    NaN   NaN   \n",
              "2                            NaN         NaN      NaN    NaN   NaN   \n",
              "3                            NaN         NaN      NaN    NaN   NaN   \n",
              "4                            NaN         NaN      NaN    NaN   NaN   \n",
              "\n",
              "   vertical_accuracy restored  \n",
              "0                NaN      NaN  \n",
              "1                NaN      NaN  \n",
              "2                NaN      NaN  \n",
              "3                NaN      NaN  \n",
              "4                NaN      NaN  \n",
              "\n",
              "[5 rows x 140 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24ccc9d4-e0ef-4897-abe2-ab0312abac39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state_id</th>\n",
              "      <th>domain</th>\n",
              "      <th>entity_id</th>\n",
              "      <th>state</th>\n",
              "      <th>event_id</th>\n",
              "      <th>last_changed</th>\n",
              "      <th>last_updated</th>\n",
              "      <th>created</th>\n",
              "      <th>old_state_id</th>\n",
              "      <th>node_id</th>\n",
              "      <th>...</th>\n",
              "      <th>end</th>\n",
              "      <th>start</th>\n",
              "      <th>status</th>\n",
              "      <th>ignoring_battery_optizimations</th>\n",
              "      <th>source_type</th>\n",
              "      <th>altitude</th>\n",
              "      <th>course</th>\n",
              "      <th>speed</th>\n",
              "      <th>vertical_accuracy</th>\n",
              "      <th>restored</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11244860</td>\n",
              "      <td>zwave</td>\n",
              "      <td>zwave.switch_cr</td>\n",
              "      <td>ready</td>\n",
              "      <td>11287622</td>\n",
              "      <td>2021-11-28 20:46:35.720593</td>\n",
              "      <td>2021-12-02 03:12:05.162304</td>\n",
              "      <td>2021-12-02 03:12:05.162304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11244861</td>\n",
              "      <td>sensor</td>\n",
              "      <td>sensor.switch_cr_exporting</td>\n",
              "      <td>False</td>\n",
              "      <td>11287623</td>\n",
              "      <td>2021-12-02 03:12:05.162807</td>\n",
              "      <td>2021-12-02 03:12:05.162807</td>\n",
              "      <td>2021-12-02 03:12:05.162807</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11244862</td>\n",
              "      <td>sensor</td>\n",
              "      <td>sensor.switch_cr_energy</td>\n",
              "      <td>6.86</td>\n",
              "      <td>11287624</td>\n",
              "      <td>2021-12-02 03:12:05.191776</td>\n",
              "      <td>2021-12-02 03:12:05.191776</td>\n",
              "      <td>2021-12-02 03:12:05.191776</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11244863</td>\n",
              "      <td>sensor</td>\n",
              "      <td>sensor.switch_cr_previous_reading_1</td>\n",
              "      <td>6.86</td>\n",
              "      <td>11287625</td>\n",
              "      <td>2021-12-02 03:12:05.220377</td>\n",
              "      <td>2021-12-02 03:12:05.220377</td>\n",
              "      <td>2021-12-02 03:12:05.220377</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11244864</td>\n",
              "      <td>sensor</td>\n",
              "      <td>sensor.switch_cr_interval_1</td>\n",
              "      <td>301</td>\n",
              "      <td>11287626</td>\n",
              "      <td>2021-12-02 03:12:05.252402</td>\n",
              "      <td>2021-12-02 03:12:05.252402</td>\n",
              "      <td>2021-12-02 03:12:05.252402</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 140 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24ccc9d4-e0ef-4897-abe2-ab0312abac39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24ccc9d4-e0ef-4897-abe2-ab0312abac39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24ccc9d4-e0ef-4897-abe2-ab0312abac39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89cca7e7-88a3-4dfb-a0bf-07c0efa68b82\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89cca7e7-88a3-4dfb-a0bf-07c0efa68b82')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89cca7e7-88a3-4dfb-a0bf-07c0efa68b82 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.tail()"
      ],
      "metadata": {
        "id": "oko6tp5P1506"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lots of nas, dropping the ones that have more than 300000 rows missing\n",
        "trial = result.copy()\n",
        "trial = trial.dropna(axis = 1, thresh =300000)\n",
        "\n",
        "\n",
        "#accessing only variables stored in kwh\n",
        "kwh_data = trial[trial.unit_of_measurement=='kWh']\n",
        "kwh_data_long = kwh_data[['node_id','value_id','last_changed','last_updated']]\n",
        "kwh_data_wide = pd.pivot(kwh_data_long, index = ['last_changed','last_updated'], columns = 'node_id', values = 'value_id')\n",
        "print(kwh_data_wide.drop_duplicates().shape)"
      ],
      "metadata": {
        "id": "5Iw-F-5U9IsH",
        "outputId": "945ae36a-983d-4e75-f904-8ffe24448d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "Index([nan], dtype='float64')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_5958/3258985082.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mkwh_data_long\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwh_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'value_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'last_changed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'last_updated'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mkwh_data_wide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwh_data_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'last_changed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'last_updated'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'node_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'value_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwh_data_wide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6816\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ignore_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6818\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6820\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6948\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6950\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: Index([nan], dtype='float64')"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3.1.1 Loading of Data Set (REDD Dataset)**\n",
        "\n",
        "> Blockzitat einfügen\n",
        "\n",
        "\n",
        "https://tokhub.github.io/dbecd/links/redd.html"
      ],
      "metadata": {
        "id": "cf0r7nG2zf2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3.1.1 Loading of Data Set (DEDDIAG Dataset)**"
      ],
      "metadata": {
        "id": "Wm31Z9Ux5N5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOI: https://springernature.figshare.com/articles/dataset/Metadata_record_for_DEDDIAG_a_domestic_electricity_demand_dataset_of_individual_appliances_in_Germany/14753556"
      ],
      "metadata": {
        "id": "FIicC6dX4MF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget = 'https://github.com/davidstintz/seminar_is/blob/main/Data/metadata%20summary.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrMq7FonDA3v",
        "outputId": "b4626ac2-1af8-44b7-cafc-a56efd1b9f7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-25 11:20:40--  http://=/\n",
            "Resolving = (=)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘=’\n",
            "--2024-11-25 11:20:40--  https://github.com/davidstintz/seminar_is/blob/main/Data/metadata%20summary.csv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘metadata summary.csv’\n",
            "\n",
            "metadata summary.cs     [  <=>               ] 163.26K   729KB/s    in 0.2s    \n",
            "\n",
            "2024-11-25 11:20:41 (729 KB/s) - ‘metadata summary.csv’ saved [167175]\n",
            "\n",
            "FINISHED --2024-11-25 11:20:41--\n",
            "Total wall clock time: 0.7s\n",
            "Downloaded: 1 files, 163K in 0.2s (729 KB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFllhmTaDuOA",
        "outputId": "de42d9de-207e-44f2-d629-bb223609f24a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'metadata summary.csv'\t sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.csv' with the name of your uploaded file\n",
        "df = pd.read_csv('metadata summary.csv')\n",
        "\n",
        "# Display the first few rows of the CSV\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "1f7tOv9KDfB4",
        "outputId": "f65e8842-657d-4f66-a737-477c42e7739e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 1 fields in line 42, saw 26\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a8faf6d14cc8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Replace 'your_file.csv' with the name of your uploaded file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metadata summary.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Display the first few rows of the CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 42, saw 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 10 lines of the file\n",
        "!head metadata summary.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaWKZMfsEDIk",
        "outputId": "66af4f27-a856-4e9e-a207-c0579a680e18"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'metadata' for reading: No such file or directory\n",
            "head: cannot open 'summary.csv' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 Explanatory Data Analysis\n",
        "Overview, do not focus on all the features"
      ],
      "metadata": {
        "id": "kwIPmAKhe3qW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Preprocessing of Data Set for NILM Approach"
      ],
      "metadata": {
        "id": "AT4fOZdGhyN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing of Data Sets**\n",
        "\n",
        "according Baro et al (2014) following approach is provided by NILMTK:\n",
        "\n",
        "**Downsample**\n",
        "\n",
        "**Voltage Normalisation**\n",
        "\n",
        "**Top-k appliances**\n",
        "\n"
      ],
      "metadata": {
        "id": "mBVl0smC0wCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nJlYuTSK0kCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Can be used as an example of NILM pipeline before the code with modeling: **\n",
        "following Ruano et al (2019): https://www.mdpi.com/1996-1073/12/11/2203\n",
        "\n",
        "\n",
        "**For that purpose, the main stages in NILM are:**\n",
        "\n",
        "**Data collection:** electrical data, including current, voltage, and power data, are obtained from smart meters, acquisition boards or by using specific hardware\n",
        "\n",
        "**Event detection:** an event is any change in the state of an appliance over time. An event implies variations in power and current, which can be detected in the electrical data previously collected by means of thresholds\n",
        "\n",
        "**Feature extraction:** appliances provide load signature information or features that can be used to distinguish one from another\n",
        "\n",
        "**Load identification:** using the features previously identified, a classification procedure takes place to determine which appliances are operating at a specified time or period, and/or their states.\n"
      ],
      "metadata": {
        "id": "m-_I5KtEi3ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Installtion of NILM Toolkit"
      ],
      "metadata": {
        "id": "UwpUH7ehspcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installation of NILM Toolkit\n",
        "!git clone https://github.com/nilmtk/nilmtk.git\n",
        "!pip install ./nilmtk\n",
        "!pip install ./nilm_metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFbnWYcjoT8y",
        "outputId": "1fdd1c35-e86d-4b80-941d-f5cbd7c1d9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'nilmtk' already exists and is not an empty directory.\n",
            "Processing ./nilmtk\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from nilmtk==0.4.0.dev1+git.4577230) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from nilmtk==0.4.0.dev1+git.4577230) (1.26.4)\n",
            "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from nilmtk==0.4.0.dev1+git.4577230) (3.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nilmtk==0.4.0.dev1+git.4577230) (1.13.1)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.10/dist-packages (from nilmtk==0.4.0.dev1+git.4577230) (3.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from nilmtk==0.4.0.dev1+git.4577230) (1.5.2)\n",
            "Requirement already satisfied: hmmlearn>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from nilmtk==0.4.0.dev1+git.4577230) (0.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from nilmtk==0.4.0.dev1+git.4577230) (6.0.2)\n",
            "Requirement already satisfied: matplotlib==3.1.3 in /usr/local/lib/python3.10/dist-packages (from nilmtk==0.4.0.dev1+git.4577230) (3.1.3)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.10/dist-packages (from nilmtk==0.4.0.dev1+git.4577230) (4.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.1.3->nilmtk==0.4.0.dev1+git.4577230) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.1.3->nilmtk==0.4.0.dev1+git.4577230) (1.4.7)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.1.3->nilmtk==0.4.0.dev1+git.4577230) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.1.3->nilmtk==0.4.0.dev1+git.4577230) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1.0->nilmtk==0.4.0.dev1+git.4577230) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1.0->nilmtk==0.4.0.dev1+git.4577230) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->nilmtk==0.4.0.dev1+git.4577230) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->nilmtk==0.4.0.dev1+git.4577230) (3.5.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.0.4)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.27.2)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (6.29.5)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (5.7.2)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.2.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.14.2)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (24.2)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (75.1.0)\n",
            "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.1.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (6.3.3)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (5.7.1)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables->nilmtk==0.4.0.dev1+git.4577230) (2.10.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from tables->nilmtk==0.4.0.dev1+git.4577230) (9.0.0)\n",
            "Requirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from tables->nilmtk==0.4.0.dev1+git.4577230) (2.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from tables->nilmtk==0.4.0.dev1+git.4577230) (4.12.2)\n",
            "Requirement already satisfied: ndindex>=1.4 in /usr/local/lib/python3.10/dist-packages (from blosc2>=2.3.0->tables->nilmtk==0.4.0.dev1+git.4577230) (1.9.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from blosc2>=2.3.0->tables->nilmtk==0.4.0.dev1+git.4577230) (1.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.14.0)\n",
            "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (8.6.3)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (24.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.3->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (3.0.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (4.3.6)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (23.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.10.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (7.16.4)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.21.0)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.8.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.16.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.9.28)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.3->nilmtk==0.4.0.dev1+git.4577230) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.2.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (21.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.21.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.0.7)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.2.3)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.8.4)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (24.11.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (0.2.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.22)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->nilmtk==0.4.0.dev1+git.4577230) (2.9.0.20241003)\n",
            "Building wheels for collected packages: nilmtk\n",
            "  Building wheel for nilmtk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.4577230-py3-none-any.whl size=279197 sha256=92f81454da53d6a00f6057135a12922a4c29a1da93b5c5adf0be5fe58c3ecbd5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qbca3ade/wheels/88/0a/7c/0c0f05729cfdb7302f1e4245b089c335af3877baddb9dd841e\n",
            "Successfully built nilmtk\n",
            "Installing collected packages: nilmtk\n",
            "  Attempting uninstall: nilmtk\n",
            "    Found existing installation: nilmtk 0.4.0.dev1+git.4577230\n",
            "    Uninstalling nilmtk-0.4.0.dev1+git.4577230:\n",
            "      Successfully uninstalled nilmtk-0.4.0.dev1+git.4577230\n",
            "Successfully installed nilmtk-0.4.0.dev1+git.4577230\n",
            "Processing ./nilm_metadata\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from nilm_metadata==0.2.5) (6.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nilm_metadata==0.2.5) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nilm_metadata==0.2.5) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->nilm_metadata==0.2.5) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->nilm_metadata==0.2.5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nilm_metadata==0.2.5) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->nilm_metadata==0.2.5) (2024.2)\n",
            "Building wheels for collected packages: nilm_metadata\n",
            "  Building wheel for nilm_metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nilm_metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24339 sha256=78728ee108fe2a7a2bb019680ba2660a142aebd33a8aa3e5bb459f606665f04a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xbww00ij/wheels/f9/5c/92/e55cfa123cc1b1429705413a17872aef0be732472f815e2f5b\n",
            "Successfully built nilm_metadata\n",
            "Installing collected packages: nilm_metadata\n",
            "  Attempting uninstall: nilm_metadata\n",
            "    Found existing installation: nilm_metadata 0.2.5\n",
            "    Uninstalling nilm_metadata-0.2.5:\n",
            "      Successfully uninstalled nilm_metadata-0.2.5\n",
            "Successfully installed nilm_metadata-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#verify installation complete\n",
        "from nilmtk import DataSet\n",
        "print(\"NILMTK successfully installed!\")"
      ],
      "metadata": {
        "id": "ifNPeja0oeTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bc2416-9063-40dd-fd18-a36ac0c76c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NILMTK successfully installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade h5py\n",
        "!pip install --upgrade tables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxVPhdU-tOps",
        "outputId": "a767de32-165a-4824-d92a-9667a4450137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.12.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.26.4)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.10/dist-packages (3.10.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from tables) (1.26.4)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables) (2.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tables) (24.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from tables) (9.0.0)\n",
            "Requirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from tables) (2.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from tables) (4.12.2)\n",
            "Requirement already satisfied: ndindex>=1.4 in /usr/local/lib/python3.10/dist-packages (from blosc2>=2.3.0->tables) (1.9.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from blosc2>=2.3.0->tables) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py==3.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2R_mTQztWY1",
        "outputId": "37398b92-5158-47a2-a97c-70d8e6f215cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==3.1.0\n",
            "  Downloading h5py-3.1.0.tar.gz (371 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/371.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m368.6/371.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.4/371.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install backend dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install backend dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tables==3.6.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7dNfV_yxlWD",
        "outputId": "1e593723-ca65-4730-99ae-c94783d71b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tables==3.6.1\n",
            "  Downloading tables-3.6.1.tar.gz (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from tables==3.6.1) (1.26.4)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables==3.6.1) (2.10.1)\n",
            "Building wheels for collected packages: tables\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tables (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for tables\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for tables\n",
            "Failed to build tables\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tables)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset_path = '/content/drive/My Drive/Seminar IS/home-assistant_v2_second.db'\n",
        "data = DataSet(dataset_path)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "rbN1Ntvzq8tS",
        "outputId": "d937e1c0-4ddc-4828-e797-9d8533ae9668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HDF5ExtError",
          "evalue": "HDF5 error back trace\n\n  File \"H5F.c\", line 836, in H5Fopen\n    unable to synchronously open file\n  File \"H5F.c\", line 796, in H5F__open_api_common\n    unable to open file\n  File \"H5VLcallback.c\", line 3863, in H5VL_file_open\n    open failed\n  File \"H5VLcallback.c\", line 3675, in H5VL__file_open\n    open failed\n  File \"H5VLnative_file.c\", line 128, in H5VL__native_file_open\n    unable to open file\n  File \"H5Fint.c\", line 2018, in H5F_open\n    unable to read superblock\n  File \"H5Fsuper.c\", line 392, in H5F__super_read\n    file signature not found\n\nEnd of HDF5 error back trace\n\nUnable to open/create file '/content/drive/My Drive/Seminar IS/home-assistant_v2_second.db'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHDF5ExtError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_5958/3175558288.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/Seminar IS/home-assistant_v2_second.db'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nilmtk/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, format)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_datastore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimport_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nilmtk/utils.py\u001b[0m in \u001b[0;36mget_datastore\u001b[0;34m(filename, format, mode)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"HDF\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mHDFDataStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CSV\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCSVDataStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nilmtk/docinherit.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nilmtk/datastore/hdfdatastore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRuntimeWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.*numpy.ufunc size changed.*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blosc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHDFDataStore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fletcher32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfletcher32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tables/file.py\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;31m# Finally, create the File instance, and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tables/file.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mHDF5ExtError\u001b[0m: HDF5 error back trace\n\n  File \"H5F.c\", line 836, in H5Fopen\n    unable to synchronously open file\n  File \"H5F.c\", line 796, in H5F__open_api_common\n    unable to open file\n  File \"H5VLcallback.c\", line 3863, in H5VL_file_open\n    open failed\n  File \"H5VLcallback.c\", line 3675, in H5VL__file_open\n    open failed\n  File \"H5VLnative_file.c\", line 128, in H5VL__native_file_open\n    unable to open file\n  File \"H5Fint.c\", line 2018, in H5F_open\n    unable to read superblock\n  File \"H5Fsuper.c\", line 392, in H5F__super_read\n    file signature not found\n\nEnd of HDF5 error back trace\n\nUnable to open/create file '/content/drive/My Drive/Seminar IS/home-assistant_v2_second.db'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare Data for suitable format for NILM\n",
        "\n",
        "#Loading a Dataset: Import and load datasets using built-in adapters:\n",
        "from nilmtk import DataSet\n",
        "dataset = DataSet('dbfile')\n",
        "\n",
        "#Preprocessing: Resample the data to a suitable frequency\n",
        "#dataset.buildings[1].elec.mains().power_series_all_data().resample('1s').mean()\n",
        "\n",
        "#Run Disaggregation: Apply algorithms to disaggregate the total energy into appliance-level consumption:\n",
        "from nilmtk.legacy.disaggregate import FHMM\n",
        "fhmm = FHMM()\n",
        "fhmm.train(dataset.buildings[1].elec)\n",
        "disaggregated = fhmm.disaggregate(test_data)\n",
        "\n",
        "#Evaluation: Compare results using NILMTK’s evaluation metrics."
      ],
      "metadata": {
        "id": "7dsd2_nQt4Kr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "43659d17-afc1-4255-be27-53cd1f5e3d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No such file as dbfile",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_5958/2040204899.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Loading a Dataset: Import and load datasets using built-in adapters:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnilmtk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dbfile'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Preprocessing: Resample the data to a suitable frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nilmtk/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, format)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_datastore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimport_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nilmtk/utils.py\u001b[0m in \u001b[0;36mget_datastore\u001b[0;34m(filename, format, mode)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"HDF\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mHDFDataStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CSV\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCSVDataStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nilmtk/docinherit.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nilmtk/datastore/hdfdatastore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file as \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No such file as dbfile"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2.2 Training and Disaggregation Algorithms**\n",
        "\n",
        "\n",
        "**Combinatorial Optimistation**\n",
        "CO finds the optimal combination of appliance states\n",
        "\n",
        "\n",
        "**Factorial Hidden Markov Model**\n",
        "- power demand of each appliance can be model as the observed value of a hidden Markov Model **(HMM)**\n",
        "- hidden component is the state of the appliance"
      ],
      "metadata": {
        "id": "Kz6-JZm413rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**3.2.3 Accuracy metrics**\n",
        "\n",
        "NILMTK provides a range of accuracy metrics\n",
        "provides both general detection metrics as well as those specific to enegery aggregation\n",
        "\n",
        "implemented in NILMTK:\n",
        "- error in total energy assigned\n",
        "- fraction of total energy assigned correctly\n",
        "- normalised error in assigned power\n",
        "- RMS error in assigned power\n",
        "- confusion matrix\n",
        "- True Positive/ False Positive Rate\n",
        "- Precision/Recall\n",
        "- F-Score\n",
        "- Hamming loss"
      ],
      "metadata": {
        "id": "fnhqSI3g3nDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. NILM Approaches and Modeling Part**"
      ],
      "metadata": {
        "id": "jC33guDGdsZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4.1 Overview\n",
        "reason-why and which models were chosen\n",
        "prepare arguments to select appraoches and why we decided to choose them (e.g. in how many of the papers this algorithm was outperforming"
      ],
      "metadata": {
        "id": "ha_KqcumiTgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common approach, as suggested by Nguyen (2020):\n",
        "\n",
        "**1. Workflow**\n",
        "\n",
        "Common steps for nonevent-based techniques (CO, FHMM, and MLE):\n",
        "- Load data (e.g., REDD) and fix a building (e.g., 1).\n",
        "- Divide data into train and test set.\n",
        "- (Optional) Select top-k devices by power.\n",
        "- Train the technique on the train set to get the model.\n",
        "- Disaggregate the total load to states (and power levels) of each appliance per\n",
        "time slice.\n",
        "- Compute the accuracy metrics such as RMSE and F-Score.\n",
        "For event-based technique (Hart85):\n",
        "- Load data (e.g., REDD) and fix a building (e.g., 1).\n",
        "- Run the technique on the total load to detect rising and falling edges.\n",
        "- Cluster the rising–falling pairs.\n",
        "- Assign found clusters to appliances, one appliance per cluster.\n",
        "- Disaggregate the total load to states (and power levels) of each appliance per\n",
        "time slice.\n",
        "- Compute the accuracy metrics such as RMSE and F-Score.\n",
        "\n",
        "**2. Dataset and Tool**\n",
        "- our dataset\n",
        "- we choose NILMTK to ease comparative study\n",
        "\n",
        "**3. Accuracy Metrics**\n",
        "\n",
        "**4. Evaluation**\n",
        "- Ground Truth and Predictions\n",
        "- RSME and F-Score\n",
        "- Runtime and Performance\n",
        "\n",
        "\n",
        "**5. Conclusion**\n"
      ],
      "metadata": {
        "id": "-bM58aVGepvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Benchmark Models\n"
      ],
      "metadata": {
        "id": "1xi5xnV-eqOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to Batra et al (2014), **Combinatorial Optimisation (CO)** and **Factorial Hidden Markov Model (FHMM)** can be considered as the main two benchmark models. Whereas CO reaches back to Harts pioneering work in 1985 and can be considered a rather basic approach, techniques based on extensions of FHMM have been used more frequently.\n",
        "NILMTK offers implementations for both of these benchmark models and the fathers of this toolkit provide reasoning for that: \"The aim of the inclusion of these algorithms is not to present state-of-the-art disaggregation results, but instead to enable new approaches to be compared to well-studied benchmark algorithms without requiring the reimplementation of such algorithms.\" (Batra et al 2014 p. 6)"
      ],
      "metadata": {
        "id": "io4yYM3TDfCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Secondary Models"
      ],
      "metadata": {
        "id": "pIq6f3eGeQ_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "035AeVfZFKQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Evaluation of Models"
      ],
      "metadata": {
        "id": "7EGD3fTmewAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Conclusion**"
      ],
      "metadata": {
        "id": "MSFd_lTIew7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Appendix"
      ],
      "metadata": {
        "id": "82noIbPwgNA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**6.1 Overview of Literature**\n",
        "\n",
        "Nipun Batra, Jack Kelly, Oliver Parson, Haimonti Dutta, William Knottenbelt, Alex Rogers, Amarjeet Singh, Mani Srivastava. NILMTK: An Open Source Toolkit for Non-intrusive Load Monitoring. In: 5th International Conference on Future Energy Systems (ACM e-Energy), Cambridge, UK. 2014. DOI: https://www.researchgate.net/publication/261673114_NILMTK_An_open_source_toolkit_for_non-intrusive_load_monitoring\n",
        "\n",
        "\n",
        "\n",
        "H. Bousbiat, A. Faustine, C. Klemenjak, L. Pereira and W. Elmenreich, \"Unlocking the Full Potential of Neural NILM: On Automation, Hyperparameters, and Modular Pipelines,\" in IEEE Transactions on Industrial Informatics, vol. 19, no. 5, pp. 7002-7010, May 2023, doi: https://ieeexplore.ieee.org/document/9889174\n",
        "\n",
        "Holmegaard, Emil, and Mikkel Baun Kjaergaard. “NILM in an Industrial Setting: A Load Characterization and Algorithm Evaluation.” 2016 IEEE International Conference on Smart Computing (SMARTCOMP) (2016): 1–8. Print. DOI: https://ieeexplore.ieee.org/document/7501709/authors#authors\n",
        "\n",
        "Hart, G.W.: Prototype nonintrusive appliance load monitor. In: MIT Energy Lab- oratory Technical Report, and Electric Power Research Institute Technical Report (1985) DOI: https://www.georgehart.com/research/Hart1985.pdf\n",
        "\n",
        "S. S. Hosseini, K. Agbossou, S. Kelouwani, and A. Cardenas, “Non- intrusive load monitoring through home energy management systems: A comprehensive review,” Renewable Sustain. Energy Rev., vol. 79, pp. 1266–1274, 2017.\n",
        "DOI: https://www.sciencedirect.com/science/article/pii/S1364032117307359?via%3Dihub\n",
        "\n",
        "\n",
        "J. Kelly and W. Knottenbelt, “Neural NILM: Deep neural networks applied to energy disaggregation,” in Proc. 2nd ACM Int. Conf. Embedded Syst. Energy-Efficient Built Environ., 2015, pp. 55–64. DOI: https://arxiv.org/pdf/1507.06594\n",
        "\n",
        "Ruano, A., Hernandez, A., Ureña, J., Ruano, M., & Garcia, J. (2019). NILM Techniques for Intelligent Home Energy Management and Ambient Assisted Living: A Review. Energies, 12(11), 2203. https://doi.org/10.3390/en12112203\n",
        "\n",
        "Suresh Chandra Satapathy, Yu-Dong Zhang, Vikrant Bhateja, Ritanjali Majhi\n",
        "Suresh Chandra. Satapathy, Intelligent Data Engineering and Analytics Frontiers in Intelligent Computing: Theory and Applications (FICTA 2020), Volume 2 SpringerLink (Online service) Singapore : Springer Singapore : Imprint: Springer ; 2021 ; XXIII, 758 p. 378 illus., 237 illus. in color. online resource. DOI: https://link.springer.com/book/10.1007/978-981-15-5679-1\n",
        "\n",
        "\n",
        "Bochao Zhao⁎, Minxiang Ye, Lina Stankovic, Vladimir Stankovic: Non-intrusive load disaggregation solutions for very low-rate smart meter data  Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow G1 1XW, UK DOI: https://strathprints.strath.ac.uk/72013/1/Zhao_etal_AE_2020_Non_intrusive_load_disaggregation_solutions.pdf\n"
      ],
      "metadata": {
        "id": "MBsKcgz2gRZu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7pdoOJEezQR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}